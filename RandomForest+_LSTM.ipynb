{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnaMji9wHou4Cj1P4Glw81",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jylee2930/Basic_BIgDataAnalysis/blob/main/RandomForest%2B_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Lq-3qDFvIR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# GPU ì„¤ì •\n",
        "print(\"TensorFlow ë²„ì „:\", tf.__version__)\n",
        "print(\"GPU ì‚¬ìš© ê°€ëŠ¥:\", tf.config.list_physical_devices('GPU'))\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
        "\n",
        "\n",
        "class RandomForestLSTMPredictor:\n",
        "    \"\"\"\n",
        "    Random Forest + LSTM í•˜ì´ë¸Œë¦¬ë“œ ê¸°ì˜¨ ì˜ˆì¸¡ ëª¨ë¸\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sequence_length=30, rf_n_estimators=100, lstm_units=64):\n",
        "        \"\"\"\n",
        "        ì´ˆê¸°í™”\n",
        "\n",
        "        Args:\n",
        "            sequence_length (int): LSTMìš© ì‹œí€€ìŠ¤ ê¸¸ì´\n",
        "            rf_n_estimators (int): Random Forestì˜ íŠ¸ë¦¬ ê°œìˆ˜\n",
        "            lstm_units (int): LSTM ìœ ë‹› ìˆ˜\n",
        "        \"\"\"\n",
        "        self.sequence_length = sequence_length\n",
        "        self.rf_n_estimators = rf_n_estimators\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        # ëª¨ë¸ë“¤\n",
        "        self.rf_model = None\n",
        "        self.lstm_model = None\n",
        "\n",
        "        # ìŠ¤ì¼€ì¼ëŸ¬ë“¤\n",
        "        self.scaler_rf_features = StandardScaler()\n",
        "        self.scaler_lstm_target = MinMaxScaler()\n",
        "\n",
        "        # ë°ì´í„° ì €ì¥\n",
        "        self.data = None\n",
        "        self.rf_feature_cols = None\n",
        "        self.lstm_feature_cols = None\n",
        "\n",
        "        # í›ˆë ¨ ê¸°ë¡\n",
        "        self.history = None\n",
        "\n",
        "    def load_and_preprocess_data(self, filepath):\n",
        "        \"\"\"\n",
        "        ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "        \"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Random Forest + LSTM í•˜ì´ë¸Œë¦¬ë“œ ê¸°ì˜¨ ì˜ˆì¸¡ ëª¨ë¸\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œì‘\")\n",
        "\n",
        "        # CSV íŒŒì¼ ì½ê¸°\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # ë‚ ì§œ ì»¬ëŸ¼ ì •ë¦¬\n",
        "        df['date'] = df['date'].str.replace('\\t', '').str.strip()\n",
        "        df = df.dropna(subset=['date', 'mean_tmp', 'min_tmp', 'max_tmp'])\n",
        "        df = df[df['date'] != '']\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "        print(f\"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ì¼ì˜ ê¸°ì˜¨ ë°ì´í„°\")\n",
        "        print(f\"ë°ì´í„° ê¸°ê°„: {df['date'].min().strftime('%Y-%m-%d')} ~ {df['date'].max().strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        # ê¸°ë³¸ ë‚ ì§œ íŠ¹ì„±\n",
        "        df['year'] = df['date'].dt.year\n",
        "        df['month'] = df['date'].dt.month\n",
        "        df['day'] = df['date'].dt.day\n",
        "        df['day_of_year'] = df['date'].dt.dayofyear\n",
        "        df['day_of_week'] = df['date'].dt.dayofweek\n",
        "        df['quarter'] = df['date'].dt.quarter\n",
        "\n",
        "        # ê³„ì ˆì„± íŠ¹ì„± (ìˆœí™˜ì )\n",
        "        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "        df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
        "        df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
        "        df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "        df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "\n",
        "        # ê¸°ì˜¨ ê´€ë ¨ íŠ¹ì„±\n",
        "        df['temp_range'] = df['max_tmp'] - df['min_tmp']\n",
        "        df['temp_mid'] = (df['max_tmp'] + df['min_tmp']) / 2\n",
        "\n",
        "        # ì´ë™í‰ê·  íŠ¹ì„±\n",
        "        for window in [3, 7, 14, 30]:\n",
        "            df[f'mean_tmp_ma_{window}'] = df['mean_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "            df[f'temp_range_ma_{window}'] = df['temp_range'].rolling(window=window, min_periods=1).mean()\n",
        "            df[f'min_tmp_ma_{window}'] = df['min_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "            df[f'max_tmp_ma_{window}'] = df['max_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "        # ì´ë™í‘œì¤€í¸ì°¨\n",
        "        for window in [7, 14]:\n",
        "            df[f'mean_tmp_std_{window}'] = df['mean_tmp'].rolling(window=window, min_periods=1).std()\n",
        "\n",
        "        # ê¸°ì˜¨ ë³€í™”ìœ¨\n",
        "        df['temp_change_1d'] = df['mean_tmp'].diff(1)\n",
        "        df['temp_change_3d'] = df['mean_tmp'].diff(3)\n",
        "        df['temp_change_7d'] = df['mean_tmp'].diff(7)\n",
        "\n",
        "        # ê³„ì ˆë³„ ì´ìƒê°’\n",
        "        monthly_mean = df.groupby('month')['mean_tmp'].transform('mean')\n",
        "        df['temp_seasonal_anomaly'] = df['mean_tmp'] - monthly_mean\n",
        "\n",
        "        # ê³¼ê±° ê¸°ì˜¨ íŒ¨í„´ (Random Forestìš©)\n",
        "        for lag in [1, 2, 3, 7, 14]:\n",
        "            df[f'mean_tmp_lag_{lag}'] = df['mean_tmp'].shift(lag)\n",
        "            df[f'temp_range_lag_{lag}'] = df['temp_range'].shift(lag)\n",
        "\n",
        "        # ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "        df[numeric_cols] = df[numeric_cols].fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "        # ë‚¨ì€ ê²°ì¸¡ê°’ ì œê±°\n",
        "        df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "        print(f\"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: ì´ {len(df.columns)}ê°œ íŠ¹ì„±\")\n",
        "\n",
        "        self.data = df\n",
        "        return df\n",
        "\n",
        "    def prepare_rf_features(self, df):\n",
        "        \"\"\"\n",
        "        Random Forestë¥¼ ìœ„í•œ íŠ¹ì„± ì¤€ë¹„\n",
        "        \"\"\"\n",
        "        self.rf_feature_cols = [\n",
        "            'month', 'day_of_year', 'day_of_week', 'quarter',\n",
        "            'month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos',\n",
        "            'day_of_week_sin', 'day_of_week_cos',\n",
        "            'min_tmp', 'max_tmp', 'temp_range', 'temp_mid',\n",
        "            'mean_tmp_ma_3', 'mean_tmp_ma_7', 'mean_tmp_ma_14', 'mean_tmp_ma_30',\n",
        "            'temp_range_ma_3', 'temp_range_ma_7', 'temp_range_ma_14',\n",
        "            'min_tmp_ma_3', 'min_tmp_ma_7', 'max_tmp_ma_3', 'max_tmp_ma_7',\n",
        "            'mean_tmp_std_7', 'mean_tmp_std_14',\n",
        "            'temp_change_1d', 'temp_change_3d', 'temp_change_7d',\n",
        "            'temp_seasonal_anomaly',\n",
        "            'mean_tmp_lag_1', 'mean_tmp_lag_2', 'mean_tmp_lag_3',\n",
        "            'mean_tmp_lag_7', 'mean_tmp_lag_14',\n",
        "            'temp_range_lag_1', 'temp_range_lag_3', 'temp_range_lag_7'\n",
        "        ]\n",
        "\n",
        "        return df[self.rf_feature_cols].values\n",
        "\n",
        "    def prepare_lstm_data(self, df, target_col='mean_tmp'):\n",
        "        \"\"\"\n",
        "        LSTMì„ ìœ„í•œ ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„\n",
        "        \"\"\"\n",
        "        # LSTMìš© íŠ¹ì„± ì„ íƒ\n",
        "        self.lstm_feature_cols = [\n",
        "            'mean_tmp', 'min_tmp', 'max_tmp', 'temp_range', 'temp_mid',\n",
        "            'month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos',\n",
        "            'mean_tmp_ma_3', 'mean_tmp_ma_7', 'mean_tmp_ma_14',\n",
        "            'temp_change_1d', 'temp_change_3d', 'temp_seasonal_anomaly'\n",
        "        ]\n",
        "\n",
        "        # íŠ¹ì„± ë°ì´í„° ì¶”ì¶œ\n",
        "        feature_data = df[self.lstm_feature_cols].values\n",
        "\n",
        "        # íƒ€ê²Ÿ ë°ì´í„°\n",
        "        target_data = df[target_col].values.reshape(-1, 1)\n",
        "        target_scaled = self.scaler_lstm_target.fit_transform(target_data)\n",
        "\n",
        "        # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±\n",
        "        X, y = [], []\n",
        "\n",
        "        for i in range(self.sequence_length, len(feature_data)):\n",
        "            X.append(feature_data[i-self.sequence_length:i])\n",
        "            y.append(target_scaled[i])\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        print(f\"LSTM ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:\")\n",
        "        print(f\"X shape: {X.shape} (samples, timesteps, features)\")\n",
        "        print(f\"y shape: {y.shape}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def split_data(self, df, train_ratio=0.7, val_ratio=0.15):\n",
        "        \"\"\"\n",
        "        ì‹œê³„ì—´ ë°ì´í„° ë¶„í• \n",
        "        \"\"\"\n",
        "        n_samples = len(df)\n",
        "        train_size = int(n_samples * train_ratio)\n",
        "        val_size = int(n_samples * val_ratio)\n",
        "\n",
        "        train_df = df[:train_size].copy()\n",
        "        val_df = df[train_size:train_size + val_size].copy()\n",
        "        test_df = df[train_size + val_size:].copy()\n",
        "\n",
        "        print(f\"ë°ì´í„° ë¶„í• :\")\n",
        "        print(f\"í›ˆë ¨: {len(train_df)}ì¼, ê²€ì¦: {len(val_df)}ì¼, í…ŒìŠ¤íŠ¸: {len(test_df)}ì¼\")\n",
        "\n",
        "        return train_df, val_df, test_df\n",
        "\n",
        "    def train_random_forest(self, train_df, val_df):\n",
        "        \"\"\"\n",
        "        Random Forest ëª¨ë¸ í›ˆë ¨\n",
        "        \"\"\"\n",
        "        print(\"\\nRandom Forest ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
        "\n",
        "        # íŠ¹ì„± ì¤€ë¹„\n",
        "        X_train = self.prepare_rf_features(train_df)\n",
        "        y_train = train_df['mean_tmp'].values\n",
        "        X_val = self.prepare_rf_features(val_df)\n",
        "        y_val = val_df['mean_tmp'].values\n",
        "\n",
        "        # íŠ¹ì„± ì •ê·œí™”\n",
        "        X_train_scaled = self.scaler_rf_features.fit_transform(X_train)\n",
        "        X_val_scaled = self.scaler_rf_features.transform(X_val)\n",
        "\n",
        "        # Random Forest ëª¨ë¸ ìƒì„± ë° í›ˆë ¨\n",
        "        self.rf_model = RandomForestRegressor(\n",
        "            n_estimators=self.rf_n_estimators,\n",
        "            max_depth=20,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            max_features='sqrt',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        self.rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # ê²€ì¦ ì„±ëŠ¥\n",
        "        y_val_pred = self.rf_model.predict(X_val_scaled)\n",
        "        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "        val_mae = mean_absolute_error(y_val, y_val_pred)\n",
        "        val_r2 = r2_score(y_val, y_val_pred)\n",
        "\n",
        "        print(f\"Random Forest ê²€ì¦ ì„±ëŠ¥:\")\n",
        "        print(f\"RMSE: {val_rmse:.3f}Â°C, MAE: {val_mae:.3f}Â°C, RÂ²: {val_r2:.3f}\")\n",
        "\n",
        "        # íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': self.rf_feature_cols,\n",
        "            'importance': self.rf_model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        print(f\"ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±:\")\n",
        "        for i in range(min(10, len(feature_importance))):\n",
        "            feat = feature_importance.iloc[i]\n",
        "            print(f\"      {i+1:2d}. {feat['feature']:<20} ({feat['importance']:.4f})\")\n",
        "\n",
        "        return val_rmse, val_mae, val_r2\n",
        "\n",
        "    def build_lstm_model(self, input_shape):\n",
        "        \"\"\"\n",
        "        LSTM ëª¨ë¸ êµ¬ì¶•\n",
        "        \"\"\"\n",
        "        model = Sequential([\n",
        "            # ì²« ë²ˆì§¸ LSTM ë ˆì´ì–´\n",
        "            LSTM(self.lstm_units * 2, return_sequences=True, input_shape=input_shape,\n",
        "                 dropout=0.2, recurrent_dropout=0.2),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            # ë‘ ë²ˆì§¸ LSTM ë ˆì´ì–´\n",
        "            LSTM(self.lstm_units, return_sequences=True,\n",
        "                 dropout=0.2, recurrent_dropout=0.2),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            # ì„¸ ë²ˆì§¸ LSTM ë ˆì´ì–´\n",
        "            LSTM(self.lstm_units // 2, return_sequences=False,\n",
        "                 dropout=0.2, recurrent_dropout=0.2),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            # Dense ë ˆì´ì–´ë“¤\n",
        "            Dense(64, activation='relu'),\n",
        "            Dropout(0.3),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "            Dense(16, activation='relu'),\n",
        "            Dense(1)\n",
        "        ])\n",
        "\n",
        "        # ì»´íŒŒì¼\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train_lstm(self, train_df, val_df, epochs=30, batch_size=32):\n",
        "        \"\"\"\n",
        "        LSTM ëª¨ë¸ í›ˆë ¨\n",
        "        \"\"\"\n",
        "        print(\"\\nLSTM ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
        "\n",
        "        # LSTM ë°ì´í„° ì¤€ë¹„\n",
        "        X_train, y_train = self.prepare_lstm_data(train_df)\n",
        "        X_val, y_val = self.prepare_lstm_data(val_df)\n",
        "\n",
        "        # ëª¨ë¸ êµ¬ì¶•\n",
        "        self.lstm_model = self.build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
        "\n",
        "        print(f\"LSTM ëª¨ë¸ êµ¬ì¡°:\")\n",
        "        self.lstm_model.summary()\n",
        "\n",
        "        # ì½œë°± ì„¤ì •\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7, verbose=1),\n",
        "            ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
        "        ]\n",
        "\n",
        "        # ëª¨ë¸ í›ˆë ¨\n",
        "        print(f\"ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ìµœëŒ€ {epochs} ì—í­)...\")\n",
        "        self.history = self.lstm_model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # ê²€ì¦ ì„±ëŠ¥\n",
        "        y_val_pred_scaled = self.lstm_model.predict(X_val, verbose=0)\n",
        "        y_val_pred = self.scaler_lstm_target.inverse_transform(y_val_pred_scaled).flatten()\n",
        "        y_val_actual = self.scaler_lstm_target.inverse_transform(y_val).flatten()\n",
        "\n",
        "        val_rmse = np.sqrt(mean_squared_error(y_val_actual, y_val_pred))\n",
        "        val_mae = mean_absolute_error(y_val_actual, y_val_pred)\n",
        "        val_r2 = r2_score(y_val_actual, y_val_pred)\n",
        "\n",
        "        print(f\"LSTM ê²€ì¦ ì„±ëŠ¥:\")\n",
        "        print(f\"RMSE: {val_rmse:.3f}Â°C, MAE: {val_mae:.3f}Â°C, RÂ²: {val_r2:.3f}\")\n",
        "\n",
        "        return val_rmse, val_mae, val_r2\n",
        "\n",
        "    def predict_hybrid(self, test_df, rf_weight=0.4, lstm_weight=0.6):\n",
        "        \"\"\"\n",
        "        í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì˜ˆì¸¡ (Random Forest + LSTM)\n",
        "        \"\"\"\n",
        "        print(f\"\\nğŸ”® í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘ (RF:{rf_weight:.1f}, LSTM:{lstm_weight:.1f})...\")\n",
        "\n",
        "        # Random Forest ì˜ˆì¸¡\n",
        "        X_test_rf = self.prepare_rf_features(test_df)\n",
        "        X_test_rf_scaled = self.scaler_rf_features.transform(X_test_rf)\n",
        "        rf_predictions = self.rf_model.predict(X_test_rf_scaled)\n",
        "\n",
        "        # LSTM ì˜ˆì¸¡\n",
        "        X_test_lstm, y_test_lstm = self.prepare_lstm_data(test_df)\n",
        "        lstm_pred_scaled = self.lstm_model.predict(X_test_lstm, verbose=0)\n",
        "        lstm_predictions = self.scaler_lstm_target.inverse_transform(lstm_pred_scaled).flatten()\n",
        "\n",
        "        # ì‹¤ì œê°’ (LSTM ê¸°ì¤€ìœ¼ë¡œ ë§ì¶¤)\n",
        "        actual_values = self.scaler_lstm_target.inverse_transform(y_test_lstm).flatten()\n",
        "\n",
        "        # Random Forest ì˜ˆì¸¡ê°’ì„ LSTMê³¼ ê¸¸ì´ ë§ì¶”ê¸°\n",
        "        rf_aligned = rf_predictions[self.sequence_length:]\n",
        "\n",
        "        # í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ (ê°€ì¤‘ í‰ê· )\n",
        "        hybrid_predictions = rf_weight * rf_aligned + lstm_weight * lstm_predictions\n",
        "\n",
        "        results = {\n",
        "            'actual': actual_values,\n",
        "            'rf': rf_aligned,\n",
        "            'lstm': lstm_predictions,\n",
        "            'hybrid': hybrid_predictions,\n",
        "            'test_dates': test_df['date'].iloc[self.sequence_length:].values\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_predictions(self, results):\n",
        "        \"\"\"\n",
        "        ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€\n",
        "        \"\"\"\n",
        "        print(\"\\nëª¨ë¸ ì„±ëŠ¥ í‰ê°€:\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        models = ['rf', 'lstm', 'hybrid']\n",
        "        model_names = {\n",
        "            'rf': 'Random Forest',\n",
        "            'lstm': 'LSTM',\n",
        "            'hybrid': 'RF+LSTM Hybrid'\n",
        "        }\n",
        "\n",
        "        evaluation_results = {}\n",
        "\n",
        "        for model in models:\n",
        "            actual = results['actual']\n",
        "            pred = results[model]\n",
        "\n",
        "            rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "            mae = mean_absolute_error(actual, pred)\n",
        "            r2 = r2_score(actual, pred)\n",
        "\n",
        "            evaluation_results[model] = {\n",
        "                'RMSE': rmse,\n",
        "                'MAE': mae,\n",
        "                'RÂ²': r2\n",
        "            }\n",
        "\n",
        "            print(f\"{model_names[model]:<20} RMSE: {rmse:.3f}Â°C  MAE: {mae:.3f}Â°C  RÂ²: {r2:.3f}\")\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
        "        best_model = min(evaluation_results.keys(), key=lambda x: evaluation_results[x]['RMSE'])\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"ìµœê³  ì„±ëŠ¥: {model_names[best_model]} (RMSE: {evaluation_results[best_model]['RMSE']:.3f}Â°C)\")\n",
        "\n",
        "        return evaluation_results\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"\n",
        "        LSTM í›ˆë ¨ ê³¼ì • ì‹œê°í™”\n",
        "        \"\"\"\n",
        "        if self.history is None:\n",
        "            print(\"í›ˆë ¨ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Loss ê·¸ë˜í”„\n",
        "        axes[0].plot(self.history.history['loss'], label='Training Loss', linewidth=2, color='blue')\n",
        "        axes[0].plot(self.history.history['val_loss'], label='Validation Loss', linewidth=2, color='red')\n",
        "        axes[0].set_title('LSTM Model Training Loss', fontsize=14, fontweight='bold')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss (MSE)')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # MAE ê·¸ë˜í”„\n",
        "        axes[1].plot(self.history.history['mae'], label='Training MAE', linewidth=2, color='blue')\n",
        "        axes[1].plot(self.history.history['val_mae'], label='Validation MAE', linewidth=2, color='red')\n",
        "        axes[1].set_title('LSTM Model Training MAE', fontsize=14, fontweight='bold')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('MAE')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def visualize_predictions(self, results, n_days=180):\n",
        "        \"\"\"\n",
        "        ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
        "        \"\"\"\n",
        "        print(\"\\nì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì¤‘...\")\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
        "\n",
        "        # ìƒ‰ìƒ ì„¤ì •\n",
        "        colors = {\n",
        "            'actual': '#2c3e50',\n",
        "            'rf': '#e74c3c',\n",
        "            'lstm': '#9b59b6',\n",
        "            'hybrid': '#27ae60'\n",
        "        }\n",
        "\n",
        "        # ìµœê·¼ n_daysë§Œ í‘œì‹œ\n",
        "        n_show = min(n_days, len(results['actual']))\n",
        "\n",
        "        # 1. ì‹œê³„ì—´ ì˜ˆì¸¡ ë¹„êµ\n",
        "        axes[0, 0].plot(results['actual'][-n_show:], color=colors['actual'],\n",
        "                       linewidth=2, label='Actual', alpha=0.9)\n",
        "        axes[0, 0].plot(results['rf'][-n_show:], color=colors['rf'],\n",
        "                       linewidth=1.5, label='Random Forest', alpha=0.7)\n",
        "        axes[0, 0].plot(results['lstm'][-n_show:], color=colors['lstm'],\n",
        "                       linewidth=1.5, label='LSTM', alpha=0.7)\n",
        "        axes[0, 0].plot(results['hybrid'][-n_show:], color=colors['hybrid'],\n",
        "                       linewidth=2, label='RF+LSTM Hybrid', alpha=0.8)\n",
        "\n",
        "        axes[0, 0].set_title(f'Temperature Prediction Comparison (Last {n_show} days)',\n",
        "                            fontsize=14, fontweight='bold')\n",
        "        axes[0, 0].set_xlabel('Days')\n",
        "        axes[0, 0].set_ylabel('Temperature (Â°C)')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì‚°ì ë„\n",
        "        axes[0, 1].scatter(results['actual'], results['hybrid'], alpha=0.6, s=20, color=colors['hybrid'])\n",
        "        min_val, max_val = min(results['actual'].min(), results['hybrid'].min()), \\\n",
        "                           max(results['actual'].max(), results['hybrid'].max())\n",
        "        axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, alpha=0.8)\n",
        "\n",
        "        r2_hybrid = r2_score(results['actual'], results['hybrid'])\n",
        "        axes[0, 1].set_title(f'RF+LSTM Hybrid: Actual vs Predicted (RÂ² = {r2_hybrid:.3f})',\n",
        "                            fontsize=14, fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Actual Temperature (Â°C)')\n",
        "        axes[0, 1].set_ylabel('Predicted Temperature (Â°C)')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. ì”ì°¨ ë¶„ì„\n",
        "        residuals = results['actual'] - results['hybrid']\n",
        "        axes[1, 0].scatter(results['hybrid'], residuals, alpha=0.6, s=20, color='green')\n",
        "        axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2, alpha=0.8)\n",
        "        axes[1, 0].set_title('Hybrid Model Residual Analysis', fontsize=14, fontweight='bold')\n",
        "        axes[1, 0].set_xlabel('Predicted Temperature (Â°C)')\n",
        "        axes[1, 0].set_ylabel('Residual (Actual - Predicted)')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. ì˜¤ì°¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨\n",
        "        models = ['rf', 'lstm', 'hybrid']\n",
        "        model_names = ['Random Forest', 'LSTM', 'RF+LSTM Hybrid']\n",
        "\n",
        "        for model, name, color in zip(models, model_names, [colors['rf'], colors['lstm'], colors['hybrid']]):\n",
        "            errors = results['actual'] - results[model]\n",
        "            axes[1, 1].hist(errors, bins=30, alpha=0.6, label=f'{name} (Ïƒ={np.std(errors):.2f})',\n",
        "                           color=color, density=True)\n",
        "\n",
        "        axes[1, 1].set_title('Prediction Error Distribution', fontsize=14, fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('Error (Â°C)')\n",
        "        axes[1, 1].set_ylabel('Density')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        axes[1, 1].axvline(x=0, color='red', linestyle='--', alpha=0.8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥\n",
        "        print(\"\\nìƒì„¸ ì„±ëŠ¥ ë¶„ì„:\")\n",
        "        print(f\"ì”ì°¨ í‰ê· : {residuals.mean():.3f}Â°C\")\n",
        "        print(f\"ì”ì°¨ í‘œì¤€í¸ì°¨: {residuals.std():.3f}Â°C\")\n",
        "       # print(f\"ì ˆëŒ€ ì˜¤ì°¨ ì¤‘ì•™ê°’: {np.median(np.abs(residuals)):.3f}Â°C\")\n",
        "        #print(f\"95% ì˜ˆì¸¡ êµ¬ê°„: Â±{np.percentile(np.abs(residuals), 95):.3f}Â°C\")\n",
        "\n",
        "    def predict_future(self, days_ahead=30):\n",
        "        \"\"\"\n",
        "        ë¯¸ë˜ ê¸°ì˜¨ ì˜ˆì¸¡\n",
        "        \"\"\"\n",
        "        if self.data is None:\n",
        "            print(\"ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\në¯¸ë˜ {days_ahead}ì¼ ê¸°ì˜¨ ì˜ˆì¸¡ ì¤‘...\")\n",
        "\n",
        "        # ìµœê·¼ ë°ì´í„° ì¤€ë¹„\n",
        "        recent_data = self.data.tail(max(60, self.sequence_length + 10)).copy()\n",
        "        future_predictions = []\n",
        "        future_dates = []\n",
        "\n",
        "        for day in range(days_ahead):\n",
        "            # ë‹¤ìŒ ë‚ ì§œ\n",
        "            last_date = recent_data['date'].iloc[-1]\n",
        "            next_date = last_date + pd.Timedelta(days=1)\n",
        "            future_dates.append(next_date)\n",
        "\n",
        "            # Random Forest ì˜ˆì¸¡\n",
        "            X_rf = self.prepare_rf_features(recent_data.tail(1))\n",
        "            X_rf_scaled = self.scaler_rf_features.transform(X_rf)\n",
        "            rf_pred = self.rf_model.predict(X_rf_scaled)[0]\n",
        "\n",
        "            # LSTM ì˜ˆì¸¡\n",
        "            lstm_sequence = recent_data.tail(self.sequence_length)\n",
        "            lstm_features = lstm_sequence[self.lstm_feature_cols].values\n",
        "            X_lstm = lstm_features.reshape(1, self.sequence_length, -1)\n",
        "            lstm_pred_scaled = self.lstm_model.predict(X_lstm, verbose=0)\n",
        "            lstm_pred = self.scaler_lstm_target.inverse_transform(lstm_pred_scaled)[0, 0]\n",
        "\n",
        "            # í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡\n",
        "            hybrid_pred = 0.4 * rf_pred + 0.6 * lstm_pred\n",
        "            future_predictions.append(hybrid_pred)\n",
        "\n",
        "            # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ë°ì´í„° ì—…ë°ì´íŠ¸\n",
        "            new_row = pd.DataFrame({\n",
        "                'date': [next_date],\n",
        "                'area': [114],  # ì›ì£¼ ì§€ì—­ ì½”ë“œ\n",
        "                'mean_tmp': [hybrid_pred],\n",
        "                'min_tmp': [hybrid_pred - 5],  # ê°„ë‹¨í•œ ì¶”ì •\n",
        "                'max_tmp': [hybrid_pred + 5]   # ê°„ë‹¨í•œ ì¶”ì •\n",
        "            })\n",
        "\n",
        "            # ìƒˆë¡œìš´ í–‰ì— í•„ìš”í•œ íŠ¹ì„±ë“¤ ê³„ì‚°\n",
        "            new_row['year'] = next_date.year\n",
        "            new_row['month'] = next_date.month\n",
        "            new_row['day'] = next_date.day\n",
        "            new_row['day_of_year'] = next_date.dayofyear\n",
        "            new_row['day_of_week'] = next_date.dayofweek\n",
        "            new_row['quarter'] = next_date.quarter\n",
        "\n",
        "            new_row['month_sin'] = np.sin(2 * np.pi * next_date.month / 12)\n",
        "            new_row['month_cos'] = np.cos(2 * np.pi * next_date.month / 12)\n",
        "            new_row['day_of_year_sin'] = np.sin(2 * np.pi * next_date.dayofyear / 365)\n",
        "            new_row['day_of_year_cos'] = np.cos(2 * np.pi * next_date.dayofyear / 365)\n",
        "            new_row['day_of_week_sin'] = np.sin(2 * np.pi * next_date.dayofweek / 7)\n",
        "            new_row['day_of_week_cos'] = np.cos(2 * np.pi * next_date.dayofweek / 7)\n",
        "\n",
        "            new_row['temp_range'] = 10  # ì¶”ì •ê°’\n",
        "            new_row['temp_mid'] = hybrid_pred\n",
        "\n",
        "            # ë°ì´í„° ì¶”ê°€\n",
        "            recent_data = pd.concat([recent_data, new_row], ignore_index=True)\n",
        "\n",
        "            # ì´ë™í‰ê·  ë“± íŠ¹ì„± ì¬ê³„ì‚°\n",
        "            for window in [3, 7, 14, 30]:\n",
        "                recent_data[f'mean_tmp_ma_{window}'] = recent_data['mean_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "                recent_data[f'temp_range_ma_{window}'] = recent_data['temp_range'].rolling(window=window, min_periods=1).mean()\n",
        "                recent_data[f'min_tmp_ma_{window}'] = recent_data['min_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "                recent_data[f'max_tmp_ma_{window}'] = recent_data['max_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "            for window in [7, 14]:\n",
        "                recent_data[f'mean_tmp_std_{window}'] = recent_data['mean_tmp'].rolling(window=window, min_periods=1).std()\n",
        "\n",
        "            recent_data['temp_change_1d'] = recent_data['mean_tmp'].diff(1)\n",
        "            recent_data['temp_change_3d'] = recent_data['mean_tmp'].diff(3)\n",
        "            recent_data['temp_change_7d'] = recent_data['mean_tmp'].diff(7)\n",
        "\n",
        "            monthly_mean = recent_data.groupby('month')['mean_tmp'].transform('mean')\n",
        "            recent_data['temp_seasonal_anomaly'] = recent_data['mean_tmp'] - monthly_mean\n",
        "\n",
        "            for lag in [1, 2, 3, 7, 14]:\n",
        "                recent_data[f'mean_tmp_lag_{lag}'] = recent_data['mean_tmp'].shift(lag)\n",
        "                recent_data[f'temp_range_lag_{lag}'] = recent_data['temp_range'].shift(lag)\n",
        "\n",
        "            # ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
        "            numeric_cols = recent_data.select_dtypes(include=[np.number]).columns\n",
        "            recent_data[numeric_cols] = recent_data[numeric_cols].fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "            if (day + 1) % 7 == 0:\n",
        "                print(f\"   {day+1:2d}ì¼ í›„ ({next_date.strftime('%Y-%m-%d')}): {hybrid_pred:.1f}Â°C\")\n",
        "\n",
        "        # ë¯¸ë˜ ì˜ˆì¸¡ ì‹œê°í™”\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        # ìµœê·¼ ì‹¤ì œ ë°ì´í„°\n",
        "        recent_actual = self.data.tail(60)\n",
        "        plt.plot(recent_actual['date'], recent_actual['mean_tmp'],\n",
        "                'b-', label='Recent Actual', linewidth=2, alpha=0.8)\n",
        "\n",
        "        # ë¯¸ë˜ ì˜ˆì¸¡ ë°ì´í„°\n",
        "        plt.plot(future_dates, future_predictions,\n",
        "                'r--', label='RF+LSTM Hybrid Prediction', linewidth=2, marker='o', markersize=4)\n",
        "\n",
        "        plt.axvline(x=self.data['date'].iloc[-1], color='gray', linestyle=':', alpha=0.7,\n",
        "                   label='Prediction Start')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Mean Temperature (Â°C)')\n",
        "        plt.title(f'Wonju Temperature Prediction - RF+LSTM Hybrid Model ({days_ahead} days)',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\n ë¯¸ë˜ ì˜ˆì¸¡ ìš”ì•½:\")\n",
        "        print(f\"   í‰ê·  ì˜ˆì¸¡ ê¸°ì˜¨: {np.mean(future_predictions):.1f}Â°C\")\n",
        "        print(f\"   ìµœê³  ì˜ˆì¸¡ ê¸°ì˜¨: {np.max(future_predictions):.1f}Â°C\")\n",
        "        print(f\"   ìµœì € ì˜ˆì¸¡ ê¸°ì˜¨: {np.min(future_predictions):.1f}Â°C\")\n",
        "        print(f\"   ê¸°ì˜¨ ë³€ë™ ë²”ìœ„: {np.max(future_predictions) - np.min(future_predictions):.1f}Â°C\")\n",
        "\n",
        "        return future_predictions, future_dates\n",
        "\n",
        "    def run_complete_pipeline(self, filepath):\n",
        "        \"\"\"\n",
        "        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
        "        \"\"\"\n",
        "        print(\"Random Forest + LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘\")\n",
        "\n",
        "        # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "        df = self.load_and_preprocess_data(filepath)\n",
        "\n",
        "        # 2. ë°ì´í„° ë¶„í• \n",
        "        train_df, val_df, test_df = self.split_data(df)\n",
        "\n",
        "        # 3. Random Forest í›ˆë ¨\n",
        "        rf_metrics = self.train_random_forest(train_df, val_df)\n",
        "\n",
        "        # 4. LSTM í›ˆë ¨\n",
        "        lstm_metrics = self.train_lstm(train_df, val_df)\n",
        "\n",
        "        # 5. í›ˆë ¨ ê³¼ì • ì‹œê°í™”\n",
        "        self.plot_training_history()\n",
        "\n",
        "        # 6. í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡\n",
        "        results = self.predict_hybrid(test_df)\n",
        "\n",
        "        # 7. ì„±ëŠ¥ í‰ê°€\n",
        "        evaluation = self.evaluate_predictions(results)\n",
        "\n",
        "        # 8. ê²°ê³¼ ì‹œê°í™”\n",
        "        self.visualize_predictions(results)\n",
        "\n",
        "        # 9. ë¯¸ë˜ ì˜ˆì¸¡\n",
        "        future_pred, future_dates = self.predict_future(days_ahead=30)\n",
        "\n",
        "        print(\"\\níŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
        "\n",
        "        return {\n",
        "            'data': df,\n",
        "            'results': results,\n",
        "            'evaluation': evaluation,\n",
        "            'future_predictions': future_pred,\n",
        "            'future_dates': future_dates\n",
        "        }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‚¬ìš© ì˜ˆì œ\n",
        "if __name__ == \"__main__\":\n",
        "    # ëª¨ë¸ ì´ˆê¸°í™”\n",
        "    predictor = RandomForestLSTMPredictor(\n",
        "        sequence_length=30,      # LSTM ì‹œí€€ìŠ¤ ê¸¸ì´\n",
        "        rf_n_estimators=100,     # Random Forest íŠ¸ë¦¬ ê°œìˆ˜\n",
        "        lstm_units=64           # LSTM ìœ ë‹› ìˆ˜\n",
        "    )\n",
        "\n",
        "    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
        "    # íŒŒì¼ ê²½ë¡œë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”\n",
        "    file_path = '/content/OBS_ASOS_wonju(10y).csv'\n",
        "\n",
        "    try:\n",
        "        pipeline_results = predictor.run_complete_pipeline(file_path)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Random Forest + LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # ì¶”ê°€ ë¶„ì„ì´ë‚˜ ì˜ˆì¸¡ì´ í•„ìš”í•œ ê²½ìš°\n",
        "        # predictor.predict_future(days_ahead=60)  # 60ì¼ ì˜ˆì¸¡\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
        "        print(\" íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
        "    except Exception as e:\n",
        "        print(f\" ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "\n",
        "\n",
        "# ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•œ ì¶”ê°€ í•¨ìˆ˜ë“¤\n",
        "def compare_individual_models(predictor, test_df):\n",
        "    \"\"\"\n",
        "    ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ìƒì„¸ ë¹„êµ\n",
        "    \"\"\"\n",
        "    print(\"\\nê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ìƒì„¸ ë¶„ì„\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Random Forestë§Œ ì‚¬ìš©í•œ ì˜ˆì¸¡\n",
        "    X_test_rf = predictor.prepare_rf_features(test_df)\n",
        "    X_test_rf_scaled = predictor.scaler_rf_features.transform(X_test_rf)\n",
        "    rf_only_pred = predictor.rf_model.predict(X_test_rf_scaled)\n",
        "\n",
        "    # LSTMë§Œ ì‚¬ìš©í•œ ì˜ˆì¸¡\n",
        "    X_test_lstm, y_test_lstm = predictor.prepare_lstm_data(test_df)\n",
        "    lstm_pred_scaled = predictor.lstm_model.predict(X_test_lstm, verbose=0)\n",
        "    lstm_only_pred = predictor.scaler_lstm_target.inverse_transform(lstm_pred_scaled).flatten()\n",
        "\n",
        "    # ì‹¤ì œê°’ (ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°)\n",
        "    actual_full = test_df['mean_tmp'].values\n",
        "    actual_lstm = predictor.scaler_lstm_target.inverse_transform(y_test_lstm).flatten()\n",
        "\n",
        "    # Random Forest ì„±ëŠ¥ (ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°)\n",
        "    rf_rmse = np.sqrt(mean_squared_error(actual_full, rf_only_pred))\n",
        "    rf_mae = mean_absolute_error(actual_full, rf_only_pred)\n",
        "    rf_r2 = r2_score(actual_full, rf_only_pred)\n",
        "\n",
        "    # LSTM ì„±ëŠ¥\n",
        "    lstm_rmse = np.sqrt(mean_squared_error(actual_lstm, lstm_only_pred))\n",
        "    lstm_mae = mean_absolute_error(actual_lstm, lstm_only_pred)\n",
        "    lstm_r2 = r2_score(actual_lstm, lstm_only_pred)\n",
        "\n",
        "    print(f\"Random Forest ë‹¨ë…:\")\n",
        "    print(f\"  RMSE: {rf_rmse:.3f}Â°C, MAE: {rf_mae:.3f}Â°C, RÂ²: {rf_r2:.3f}\")\n",
        "    print(f\"LSTM ë‹¨ë…:\")\n",
        "    print(f\"  RMSE: {lstm_rmse:.3f}Â°C, MAE: {lstm_mae:.3f}Â°C, RÂ²: {lstm_r2:.3f}\")\n",
        "\n",
        "    return {\n",
        "        'rf_only': {'RMSE': rf_rmse, 'MAE': rf_mae, 'RÂ²': rf_r2},\n",
        "        'lstm_only': {'RMSE': lstm_rmse, 'MAE': lstm_mae, 'RÂ²': lstm_r2}\n",
        "    }\n",
        "\n",
        "\n",
        "def analyze_seasonal_performance(results):\n",
        "    \"\"\"\n",
        "    ê³„ì ˆë³„ ì„±ëŠ¥ ë¶„ì„\n",
        "    \"\"\"\n",
        "    print(\"\\n ê³„ì ˆë³„ ì„±ëŠ¥ ë¶„ì„\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # ë‚ ì§œ ì •ë³´ê°€ ìˆë‹¤ë©´ ê³„ì ˆë³„ë¡œ ë¶„ì„\n",
        "    if 'test_dates' in results:\n",
        "        dates = pd.to_datetime(results['test_dates'])\n",
        "        months = dates.month\n",
        "\n",
        "        seasons = {\n",
        "            'Spring (3-5ì›”)': [3, 4, 5],\n",
        "            'Summer (6-8ì›”)': [6, 7, 8],\n",
        "            'Autumn (9-11ì›”)': [9, 10, 11],\n",
        "            'Winter (12-2ì›”)': [12, 1, 2]\n",
        "        }\n",
        "\n",
        "        for season_name, season_months in seasons.items():\n",
        "            mask = months.isin(season_months)\n",
        "            if np.sum(mask) > 0:\n",
        "                actual_season = results['actual'][mask]\n",
        "                hybrid_season = results['hybrid'][mask]\n",
        "\n",
        "                rmse = np.sqrt(mean_squared_error(actual_season, hybrid_season))\n",
        "                mae = mean_absolute_error(actual_season, hybrid_season)\n",
        "\n",
        "                print(f\"{season_name:<15} RMSE: {rmse:.3f}Â°C  MAE: {mae:.3f}Â°C  ({np.sum(mask):3d}ì¼)\")\n",
        "\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜\n",
        "def optimize_hybrid_weights(predictor, val_df, weight_range=np.arange(0.1, 1.0, 0.1)):\n",
        "    \"\"\"\n",
        "    í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì˜ ìµœì  ê°€ì¤‘ì¹˜ ì°¾ê¸°\n",
        "    \"\"\"\n",
        "    print(\"\\ní•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ìµœì í™”\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    best_rmse = float('inf')\n",
        "    best_weights = (0.5, 0.5)\n",
        "\n",
        "    results_list = []\n",
        "\n",
        "    for rf_weight in weight_range:\n",
        "        lstm_weight = 1.0 - rf_weight\n",
        "\n",
        "        # ê²€ì¦ ë°ì´í„°ë¡œ ì˜ˆì¸¡\n",
        "        val_results = predictor.predict_hybrid(val_df, rf_weight, lstm_weight)\n",
        "        rmse = np.sqrt(mean_squared_error(val_results['actual'], val_results['hybrid']))\n",
        "\n",
        "        results_list.append((rf_weight, lstm_weight, rmse))\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_weights = (rf_weight, lstm_weight)\n",
        "\n",
        "        print(f\"RF:{rf_weight:.1f}, LSTM:{lstm_weight:.1f} -> RMSE: {rmse:.3f}Â°C\")\n",
        "\n",
        "    print(f\"\\nìµœì  ê°€ì¤‘ì¹˜: RF {best_weights[0]:.1f}, LSTM {best_weights[1]:.1f}\")\n",
        "    print(f\"   ìµœì  RMSE: {best_rmse:.3f}Â°C\")\n",
        "\n",
        "    return best_weights, results_list"
      ],
      "metadata": {
        "id": "vFxTFf5AHja7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}