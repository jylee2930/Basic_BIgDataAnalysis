{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdMmf4uV5yD4g01US8V8Rw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jylee2930/Basic_BIgDataAnalysis/blob/main/Teampreture(LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow 업데이트\n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# 런타임 재시작 후 확인\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow 버전:\", tf.__version__)"
      ],
      "metadata": {
        "id": "GI3nDDkK8m8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSjaJixs3PTH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 한글 폰트 설정\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# GPU 설정 (있는 경우)\n",
        "print(\"GPU 사용 가능:\", tf.config.list_physical_devices('GPU'))\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
        "\n",
        "class TemperatureLSTMPredictor:\n",
        "    def __init__(self, sequence_length=30, prediction_horizon=1):\n",
        "        \"\"\"\n",
        "        LSTM 기온 예측 모델\n",
        "\n",
        "        Args:\n",
        "            sequence_length (int): 과거 몇 일의 데이터를 사용할지\n",
        "            prediction_horizon (int): 몇 일 후를 예측할지\n",
        "        \"\"\"\n",
        "        self.sequence_length = sequence_length\n",
        "        self.prediction_horizon = prediction_horizon\n",
        "        self.model = None\n",
        "        self.scaler_X = None\n",
        "        self.scaler_y = None\n",
        "        self.history = None\n",
        "\n",
        "    def load_and_preprocess_data(self, file_path):\n",
        "        \"\"\"\n",
        "        데이터 로드 및 전처리\n",
        "        \"\"\"\n",
        "        # CSV 파일 읽기\n",
        "        df = pd.read_csv('/content/wonju_temp.csv')\n",
        "\n",
        "        # 날짜 컬럼 정리\n",
        "        df['date'] = df['date'].str.replace('\\t', '').str.strip()\n",
        "        df = df.dropna(subset=['date', 'mean_tmp', 'min_tmp', 'max_tmp'])\n",
        "        df = df[df['date'] != '']\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "        print(f\"데이터 로드 완료: {len(df)}일의 기온 데이터\")\n",
        "        print(f\"데이터 기간: {df['date'].min().strftime('%Y-%m-%d')} ~ {df['date'].max().strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_features(self, df):\n",
        "        \"\"\"\n",
        "        LSTM을 위한 특성 생성\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # 기본 날짜 특성\n",
        "        df['year'] = df['date'].dt.year\n",
        "        df['month'] = df['date'].dt.month\n",
        "        df['day'] = df['date'].dt.day\n",
        "        df['day_of_year'] = df['date'].dt.dayofyear\n",
        "        df['day_of_week'] = df['date'].dt.dayofweek\n",
        "        df['quarter'] = df['date'].dt.quarter\n",
        "\n",
        "        # 계절성 특성 (순환적)\n",
        "        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "        df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
        "        df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
        "        df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "        df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "\n",
        "        # 기온 관련 특성\n",
        "        df['temp_range'] = df['max_tmp'] - df['min_tmp']\n",
        "        df['temp_mid'] = (df['max_tmp'] + df['min_tmp']) / 2\n",
        "\n",
        "        # 이동평균 특성\n",
        "        for window in [3, 7, 14, 30]:\n",
        "            df[f'mean_tmp_ma_{window}'] = df['mean_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "            df[f'temp_range_ma_{window}'] = df['temp_range'].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "        # 이동표준편차\n",
        "        for window in [7, 14]:\n",
        "            df[f'mean_tmp_std_{window}'] = df['mean_tmp'].rolling(window=window, min_periods=1).std()\n",
        "\n",
        "        # 기온 변화율\n",
        "        df['temp_change_1d'] = df['mean_tmp'].diff(1)\n",
        "        df['temp_change_7d'] = df['mean_tmp'].diff(7)\n",
        "\n",
        "        # 계절별 이상값\n",
        "        monthly_mean = df.groupby('month')['mean_tmp'].transform('mean')\n",
        "        df['temp_seasonal_anomaly'] = df['mean_tmp'] - monthly_mean\n",
        "\n",
        "        # 결측값 처리\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "        df[numeric_cols] = df[numeric_cols].fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "        print(f\"특성 생성 완료: 총 {len(df.columns)}개 특성\")\n",
        "        return df\n",
        "\n",
        "    def prepare_lstm_data(self, df, target_col='mean_tmp'):\n",
        "        \"\"\"\n",
        "        LSTM을 위한 시퀀스 데이터 준비\n",
        "        \"\"\"\n",
        "        # 특성 선택 (날짜, area 제외)\n",
        "        feature_cols = [col for col in df.columns if col not in ['date', 'area']]\n",
        "\n",
        "        # 데이터 추출\n",
        "        data = df[feature_cols].values\n",
        "\n",
        "        # 타겟 컬럼 인덱스 찾기\n",
        "        target_idx = df.columns.get_loc(target_col)\n",
        "\n",
        "        # 정규화\n",
        "        self.scaler_X = MinMaxScaler()\n",
        "        self.scaler_y = MinMaxScaler()\n",
        "\n",
        "        # 전체 특성 정규화\n",
        "        data_scaled = self.scaler_X.fit_transform(data)\n",
        "\n",
        "        # 타겟만 따로 정규화\n",
        "        target_data = df[target_col].values.reshape(-1, 1)\n",
        "        target_scaled = self.scaler_y.fit_transform(target_data)\n",
        "\n",
        "        # 시퀀스 데이터 생성\n",
        "        X, y = [], []\n",
        "\n",
        "        for i in range(self.sequence_length, len(data_scaled) - self.prediction_horizon + 1):\n",
        "            # 과거 sequence_length 일의 모든 특성\n",
        "            X.append(data_scaled[i-self.sequence_length:i])\n",
        "            # prediction_horizon 일 후의 타겟\n",
        "            y.append(target_scaled[i + self.prediction_horizon - 1])\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        print(f\"LSTM 데이터 준비 완료:\")\n",
        "        print(f\"X shape: {X.shape} (samples, timesteps, features)\")\n",
        "        print(f\"y shape: {y.shape}\")\n",
        "\n",
        "        return X, y, feature_cols\n",
        "\n",
        "    def split_data(self, X, y, train_ratio=0.7, val_ratio=0.15):\n",
        "        \"\"\"\n",
        "        시계열 데이터 분할 (시간 순서 유지)\n",
        "        \"\"\"\n",
        "        n_samples = len(X)\n",
        "        train_size = int(n_samples * train_ratio)\n",
        "        val_size = int(n_samples * val_ratio)\n",
        "\n",
        "        X_train = X[:train_size]\n",
        "        y_train = y[:train_size]\n",
        "\n",
        "        X_val = X[train_size:train_size + val_size]\n",
        "        y_val = y[train_size:train_size + val_size]\n",
        "\n",
        "        X_test = X[train_size + val_size:]\n",
        "        y_test = y[train_size + val_size:]\n",
        "\n",
        "        print(f\"데이터 분할 완료:\")\n",
        "        print(f\"훈련: {len(X_train)}, 검증: {len(X_val)}, 테스트: {len(X_test)}\")\n",
        "\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "    def build_model(self, input_shape):\n",
        "        \"\"\"\n",
        "        LSTM 모델 구축\n",
        "        \"\"\"\n",
        "        model = Sequential([\n",
        "            # 첫 번째 LSTM 레이어\n",
        "            LSTM(128, return_sequences=True, input_shape=input_shape, dropout=0.2, recurrent_dropout=0.2),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            # 두 번째 LSTM 레이어\n",
        "            LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            # 세 번째 LSTM 레이어\n",
        "            LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            # Dense 레이어들\n",
        "            Dense(64, activation='relu'),\n",
        "            Dropout(0.3),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "            Dense(16, activation='relu'),\n",
        "            Dense(1)  # 출력 레이어\n",
        "        ])\n",
        "\n",
        "        # 컴파일\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "        print(\"\\n=== 모델 구조 ===\")\n",
        "        model.summary()\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train_model(self, X_train, y_train, X_val, y_val, epochs=200, batch_size=32):\n",
        "        \"\"\"\n",
        "        모델 학습\n",
        "        \"\"\"\n",
        "        # 콜백 설정\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7, verbose=1),\n",
        "            ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "        ]\n",
        "\n",
        "        print(f\"\\n모델 학습 시작 (최대 {epochs} 에폭)...\")\n",
        "\n",
        "        # 모델 학습\n",
        "        self.history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(\"모델 학습 완료!\")\n",
        "\n",
        "        return self.history\n",
        "\n",
        "    def evaluate_model(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "        \"\"\"\n",
        "        모델 성능 평가\n",
        "        \"\"\"\n",
        "        # 예측\n",
        "        y_pred_train = self.model.predict(X_train, verbose=0)\n",
        "        y_pred_val = self.model.predict(X_val, verbose=0)\n",
        "        y_pred_test = self.model.predict(X_test, verbose=0)\n",
        "\n",
        "        # 역정규화\n",
        "        y_train_orig = self.scaler_y.inverse_transform(y_train)\n",
        "        y_val_orig = self.scaler_y.inverse_transform(y_val)\n",
        "        y_test_orig = self.scaler_y.inverse_transform(y_test)\n",
        "\n",
        "        y_pred_train_orig = self.scaler_y.inverse_transform(y_pred_train)\n",
        "        y_pred_val_orig = self.scaler_y.inverse_transform(y_pred_val)\n",
        "        y_pred_test_orig = self.scaler_y.inverse_transform(y_pred_test)\n",
        "\n",
        "        # 성능 계산\n",
        "        def calculate_metrics(y_true, y_pred):\n",
        "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "            mae = mean_absolute_error(y_true, y_pred)\n",
        "            r2 = r2_score(y_true, y_pred)\n",
        "            return rmse, mae, r2\n",
        "\n",
        "        train_rmse, train_mae, train_r2 = calculate_metrics(y_train_orig, y_pred_train_orig)\n",
        "        val_rmse, val_mae, val_r2 = calculate_metrics(y_val_orig, y_pred_val_orig)\n",
        "        test_rmse, test_mae, test_r2 = calculate_metrics(y_test_orig, y_pred_test_orig)\n",
        "\n",
        "        print(\"\\n=== 모델 성능 평가 ===\")\n",
        "        print(f\"훈련   - RMSE: {train_rmse:.3f}°C, MAE: {train_mae:.3f}°C, R²: {train_r2:.3f}\")\n",
        "        print(f\"검증   - RMSE: {val_rmse:.3f}°C, MAE: {val_mae:.3f}°C, R²: {val_r2:.3f}\")\n",
        "        print(f\"테스트 - RMSE: {test_rmse:.3f}°C, MAE: {test_mae:.3f}°C, R²: {test_r2:.3f}\")\n",
        "\n",
        "        return {\n",
        "            'train': (y_train_orig, y_pred_train_orig),\n",
        "            'val': (y_val_orig, y_pred_val_orig),\n",
        "            'test': (y_test_orig, y_pred_test_orig)\n",
        "        }\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"\n",
        "        학습 과정 시각화\n",
        "        \"\"\"\n",
        "        if self.history is None:\n",
        "            print(\"학습 기록이 없습니다.\")\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Loss 그래프\n",
        "        axes[0].plot(self.history.history['loss'], label='Training Loss', linewidth=2)\n",
        "        axes[0].plot(self.history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "        axes[0].set_title('Model Loss', fontsize=14)\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss (MSE)')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # MAE 그래프\n",
        "        axes[1].plot(self.history.history['mae'], label='Training MAE', linewidth=2)\n",
        "        axes[1].plot(self.history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
        "        axes[1].set_title('Model MAE', fontsize=14)\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('MAE')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def visualize_predictions(self, results, df_dates, train_size, val_size):\n",
        "        \"\"\"\n",
        "        예측 결과 시각화\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "        # 1. 전체 시계열 예측 결과\n",
        "        train_dates = df_dates[self.sequence_length:self.sequence_length + train_size]\n",
        "        val_dates = df_dates[self.sequence_length + train_size:self.sequence_length + train_size + val_size]\n",
        "        test_dates = df_dates[self.sequence_length + train_size + val_size:]\n",
        "\n",
        "        y_train_orig, y_pred_train_orig = results['train']\n",
        "        y_val_orig, y_pred_val_orig = results['val']\n",
        "        y_test_orig, y_pred_test_orig = results['test']\n",
        "\n",
        "        axes[0, 0].plot(train_dates, y_train_orig.flatten(), label='train', alpha=0.7, linewidth=1)\n",
        "        axes[0, 0].plot(val_dates, y_val_orig.flatten(), label='validation', alpha=0.8, linewidth=1.5)\n",
        "        axes[0, 0].plot(test_dates, y_test_orig.flatten(), label='test', linewidth=2)\n",
        "        axes[0, 0].plot(test_dates, y_pred_test_orig.flatten(), label='predict(test)',\n",
        "                       linestyle='--', linewidth=2)\n",
        "        axes[0, 0].set_title('Time Series Predict Result', fontsize=14)\n",
        "        axes[0, 0].set_xlabel('date')\n",
        "        axes[0, 0].set_ylabel('Mean_temp (°C)')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. 실제 vs 예측 (테스트 데이터)\n",
        "        axes[0, 1].scatter(y_test_orig, y_pred_test_orig, alpha=0.6, s=20)\n",
        "        min_val, max_val = y_test_orig.min(), y_test_orig.max()\n",
        "        axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "        axes[0, 1].set_title('Real vs Predict (Test)', fontsize=14)\n",
        "        axes[0, 1].set_xlabel('Real_mean_temp (°C)')\n",
        "        axes[0, 1].set_ylabel('Predict_mean_temp (°C)')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. 잔차 분석\n",
        "        residuals = y_test_orig.flatten() - y_pred_test_orig.flatten()\n",
        "        axes[1, 0].scatter(y_pred_test_orig, residuals, alpha=0.6, s=20, color='green')\n",
        "        axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "        axes[1, 0].set_title('Residual Analysis', fontsize=14)\n",
        "        axes[1, 0].set_xlabel('Predict Mean temp (°C)')\n",
        "        axes[1, 0].set_ylabel('resudual (real-predict)')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. 최근 예측 결과 (상세)\n",
        "        recent_period = min(60, len(test_dates))\n",
        "        axes[1, 1].plot(test_dates[-recent_period:], y_test_orig[-recent_period:].flatten(),\n",
        "                       label='real', linewidth=2, marker='o', markersize=3)\n",
        "        axes[1, 1].plot(test_dates[-recent_period:], y_pred_test_orig[-recent_period:].flatten(),\n",
        "                       label='predict', linewidth=2, marker='s', markersize=3, linestyle='--')\n",
        "        axes[1, 1].set_title('Predict Result', fontsize=14)\n",
        "        axes[1, 1].set_xlabel('date')\n",
        "        axes[1, 1].set_ylabel('Mean-temp (°C)')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # 성능 요약\n",
        "        print(\"\\n=== 상세 성능 분석 ===\")\n",
        "        print(f\"잔차 평균: {residuals.mean():.3f}°C\")\n",
        "        print(f\"잔차 표준편차: {residuals.std():.3f}°C\")\n",
        "        print(f\"절대 오차 중앙값: {np.median(np.abs(residuals)):.3f}°C\")\n",
        "        print(f\"95% 예측 구간: ±{np.percentile(np.abs(residuals), 95):.3f}°C\")\n",
        "\n",
        "    def predict_future(self, df, days_ahead=30):\n",
        "        \"\"\"\n",
        "        미래 기온 예측\n",
        "        \"\"\"\n",
        "        print(f\"\\n미래 {days_ahead}일간 기온 예측 중...\")\n",
        "\n",
        "        # 최근 데이터 가져오기\n",
        "        recent_data = df.tail(self.sequence_length + days_ahead).copy()\n",
        "\n",
        "        predictions = []\n",
        "        prediction_dates = []\n",
        "\n",
        "        for i in range(days_ahead):\n",
        "            # 다음 날짜\n",
        "            last_date = recent_data['date'].iloc[-1]\n",
        "            next_date = last_date + pd.Timedelta(days=1)\n",
        "            prediction_dates.append(next_date)\n",
        "\n",
        "            # 예측을 위한 시퀀스 데이터 준비\n",
        "            sequence_data = recent_data.tail(self.sequence_length)\n",
        "\n",
        "            # 특성 생성\n",
        "            sequence_data_with_features = self.create_features(sequence_data)\n",
        "            feature_cols = [col for col in sequence_data_with_features.columns if col not in ['date', 'area']]\n",
        "\n",
        "            # 정규화\n",
        "            sequence_scaled = self.scaler_X.transform(sequence_data_with_features[feature_cols].values)\n",
        "            X_pred = sequence_scaled.reshape(1, self.sequence_length, -1)\n",
        "\n",
        "            # 예측\n",
        "            pred_scaled = self.model.predict(X_pred, verbose=0)\n",
        "            pred_temp = self.scaler_y.inverse_transform(pred_scaled)[0, 0]\n",
        "            predictions.append(pred_temp)\n",
        "\n",
        "            # 다음 예측을 위해 데이터 업데이트\n",
        "            new_row = pd.DataFrame({\n",
        "                'date': [next_date],\n",
        "                'area': [114],  # 원주 지역 코드\n",
        "                'mean_tmp': [pred_temp],\n",
        "                'min_tmp': [pred_temp - 5],  # 간단한 추정\n",
        "                'max_tmp': [pred_temp + 5]   # 간단한 추정\n",
        "            })\n",
        "\n",
        "            recent_data = pd.concat([recent_data, new_row], ignore_index=True)\n",
        "\n",
        "            if i % 7 == 0:\n",
        "                print(f\"{i+1}일 후 ({next_date.strftime('%Y-%m-%d')}): {pred_temp:.1f}°C\")\n",
        "\n",
        "        # 예측 결과 시각화\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        # 최근 실제 데이터\n",
        "        recent_actual = df.tail(60)\n",
        "        plt.plot(recent_actual['date'], recent_actual['mean_tmp'],\n",
        "                'b-', label='Reeal temp', linewidth=2, alpha=0.8)\n",
        "\n",
        "        # 예측 데이터\n",
        "        plt.plot(prediction_dates, predictions,\n",
        "                'r--', label='LSTM Predict', linewidth=2, marker='o', markersize=4)\n",
        "\n",
        "        plt.axvline(x=df['date'].iloc[-1], color='gray', linestyle=':', alpha=0.7, label='예측 시작점')\n",
        "        plt.xlabel('date')\n",
        "        plt.ylabel('Mean_temp (°C)')\n",
        "        plt.title(f'Wonju LSTM Predict ({days_ahead}day)')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\n예측 요약:\")\n",
        "        print(f\"평균 예측 기온: {np.mean(predictions):.1f}°C\")\n",
        "        print(f\"최고 예측 기온: {np.max(predictions):.1f}°C\")\n",
        "        print(f\"최저 예측 기온: {np.min(predictions):.1f}°C\")\n",
        "\n",
        "        return predictions, prediction_dates\n",
        "\n",
        "    def fit(self, file_path, epochs=200, batch_size=32):\n",
        "        \"\"\"\n",
        "        전체 파이프라인 실행\n",
        "        \"\"\"\n",
        "        print(\"=== 원주 기온 LSTM 예측 시스템 ===\\n\")\n",
        "\n",
        "        # 1. 데이터 로드 및 전처리\n",
        "        df = self.load_and_preprocess_data(file_path)\n",
        "        df_with_features = self.create_features(df)\n",
        "\n",
        "        # 2. LSTM 데이터 준비\n",
        "        X, y, feature_cols = self.prepare_lstm_data(df_with_features)\n",
        "\n",
        "        # 3. 데이터 분할\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test = self.split_data(X, y)\n",
        "\n",
        "        # 4. 모델 구축\n",
        "        self.model = self.build_model((X.shape[1], X.shape[2]))\n",
        "\n",
        "        # 5. 모델 학습\n",
        "        self.train_model(X_train, y_train, X_val, y_val, epochs, batch_size)\n",
        "\n",
        "        # 6. 학습 과정 시각화\n",
        "        self.plot_training_history()\n",
        "\n",
        "        # 7. 성능 평가 및 시각화\n",
        "        results = self.evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "        # 8. 예측 결과 시각화\n",
        "        df_dates = df_with_features['date'].values\n",
        "        self.visualize_predictions(results, df_dates, len(X_train), len(X_val))\n",
        "\n",
        "        # 9. 미래 예측\n",
        "        predictions, dates = self.predict_future(df_with_features, days_ahead=30)\n",
        "\n",
        "        return df_with_features, results, predictions, dates\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용 예제\n",
        "def main():\n",
        "    \"\"\"\n",
        "    메인 실행 함수\n",
        "    \"\"\"\n",
        "    # LSTM 예측기 초기화\n",
        "    predictor = TemperatureLSTMPredictor(\n",
        "        sequence_length=30,      # 과거 30일 데이터 사용\n",
        "        prediction_horizon=1     # 1일 후 예측\n",
        "    )\n",
        "\n",
        "    # 모델 학습 및 예측\n",
        "    df, results, predictions, dates = predictor.fit(\n",
        "        'wonju_temp.csv',\n",
        "        epochs=30,              # 학습 에폭 수\n",
        "        batch_size=32           # 배치 크기\n",
        "    )\n",
        "\n",
        "    return predictor, df, results, predictions, dates\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    # 실행하기 전에 필요한 라이브러리 설치:\n",
        "    # pip install tensorflow pandas numpy matplotlib seaborn scikit-learn\n",
        "\n",
        "    predictor, df, results, predictions, dates = main()"
      ],
      "metadata": {
        "id": "mBN3M4tp4-8I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}