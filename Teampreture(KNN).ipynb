{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMwl2Tmbk1P8IQ4I3LY1pVg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jylee2930/Basic_BIgDataAnalysis/blob/main/Teampreture(KNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls0Wj3zMhpum"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. 데이터 로드 및 전처리\n",
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"\n",
        "    원주 기온 데이터 로드 및 전처리\n",
        "    \"\"\"\n",
        "    # CSV 파일 읽기\n",
        "    df = pd.read_csv('/content/wonju_temp.csv')\n",
        "\n",
        "    # 날짜 컬럼에서 탭 문자 제거 및 날짜 형식 변환\n",
        "    df['date'] = df['date'].str.replace('\\t', '').str.strip()\n",
        "\n",
        "    # 빈 행 제거\n",
        "    df = df.dropna(subset=['date', 'mean_tmp', 'min_tmp', 'max_tmp'])\n",
        "\n",
        "    # 날짜가 빈 문자열인 경우 제거\n",
        "    df = df[df['date'] != '']\n",
        "\n",
        "    # 날짜 형식 변환\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    # 날짜순 정렬\n",
        "    df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "    print(f\"데이터 로드 완료: {len(df)}일의 기온 데이터\")\n",
        "    print(f\"데이터 기간: {df['date'].min().strftime('%Y-%m-%d')} ~ {df['date'].max().strftime('%Y-%m-%d')}\")\n",
        "    print(f\"평균 기온 범위: {df['mean_tmp'].min():.1f}°C ~ {df['mean_tmp'].max():.1f}°C\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_features(df):\n",
        "    \"\"\"\n",
        "    시계열 특성 및 기상 특성 생성\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # 날짜 관련 특성\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['day'] = df['date'].dt.day\n",
        "    df['day_of_year'] = df['date'].dt.dayofyear\n",
        "    df['day_of_week'] = df['date'].dt.dayofweek\n",
        "    df['quarter'] = df['date'].dt.quarter\n",
        "\n",
        "    # 계절성 특성 (삼각함수로 순환적 특성 표현)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
        "    df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
        "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "\n",
        "    # 기온 범위 특성\n",
        "    df['temp_range'] = df['max_tmp'] - df['min_tmp']\n",
        "    df['temp_mid'] = (df['max_tmp'] + df['min_tmp']) / 2\n",
        "\n",
        "    # 과거 기온 정보 (lag features)\n",
        "    for lag in [1, 2, 3, 7, 14, 30]:\n",
        "        df[f'mean_tmp_lag_{lag}'] = df['mean_tmp'].shift(lag)\n",
        "        df[f'min_tmp_lag_{lag}'] = df['min_tmp'].shift(lag)\n",
        "        df[f'max_tmp_lag_{lag}'] = df['max_tmp'].shift(lag)\n",
        "        df[f'temp_range_lag_{lag}'] = df['temp_range'].shift(lag)\n",
        "\n",
        "    # 이동평균 특성\n",
        "    for window in [3, 7, 14, 30]:\n",
        "        df[f'mean_tmp_ma_{window}'] = df['mean_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "        df[f'min_tmp_ma_{window}'] = df['min_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "        df[f'max_tmp_ma_{window}'] = df['max_tmp'].rolling(window=window, min_periods=1).mean()\n",
        "        df[f'temp_range_ma_{window}'] = df['temp_range'].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "    # 이동표준편차 특성\n",
        "    for window in [7, 14, 30]:\n",
        "        df[f'mean_tmp_std_{window}'] = df['mean_tmp'].rolling(window=window, min_periods=1).std()\n",
        "        df[f'temp_range_std_{window}'] = df['temp_range'].rolling(window=window, min_periods=1).std()\n",
        "\n",
        "    # 기온 변화율 특성\n",
        "    df['mean_tmp_diff_1'] = df['mean_tmp'].diff(1)\n",
        "    df['mean_tmp_diff_7'] = df['mean_tmp'].diff(7)\n",
        "    df['temp_range_diff_1'] = df['temp_range'].diff(1)\n",
        "\n",
        "    # 계절별 평균과의 차이\n",
        "    seasonal_mean = df.groupby(['month'])['mean_tmp'].transform('mean')\n",
        "    df['temp_seasonal_anomaly'] = df['mean_tmp'] - seasonal_mean\n",
        "\n",
        "    # 연도별 추세\n",
        "    yearly_mean = df.groupby(['year'])['mean_tmp'].transform('mean')\n",
        "    df['temp_yearly_anomaly'] = df['mean_tmp'] - yearly_mean\n",
        "\n",
        "    # 결측값 처리 (앞뒤 값의 평균으로 채움)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    df[numeric_cols] = df[numeric_cols].fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "    print(f\"특성 생성 완료: 총 {len(df.columns)}개 특성\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def prepare_ml_data(df, target_col='mean_tmp'):\n",
        "    \"\"\"등으\n",
        "    머신러닝을 위한 데이터 준비\n",
        "    \"\"\"\n",
        "    # 예측에 사용할 특성 선택 (날짜, 타겟 변수, area 제외)\n",
        "    exclude_cols = ['date', 'area', target_col]\n",
        "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
        "\n",
        "    X = df[feature_cols]\n",
        "    y = df[target_col]\n",
        "\n",
        "    # 초기 30일은 lag 특성 때문에 품질이 낮을 수 있으므로 제거\n",
        "    X = X.iloc[30:]\n",
        "    y = y.iloc[30:]\n",
        "\n",
        "    print(f\"ML 데이터 준비 완료: {len(X)}개 샘플, {len(feature_cols)}개 특성\")\n",
        "    print(f\"특성 목록 (일부): {feature_cols[:10]}...\")\n",
        "\n",
        "    return X, y, feature_cols\n",
        "\n",
        "def find_optimal_k(X, y, k_range=range(1, 31), cv_folds=5):\n",
        "    \"\"\"\n",
        "    교차 검증을 통해 최적의 K 값 찾기\n",
        "    \"\"\"\n",
        "    print(\"최적의 K 값을 찾는 중...\")\n",
        "\n",
        "    # 데이터 정규화\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # 다양한 가중치 방법 테스트\n",
        "    param_grid = {\n",
        "        'n_neighbors': k_range,\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'metric': ['euclidean', 'manhattan']\n",
        "    }\n",
        "\n",
        "    knn = KNeighborsRegressor()\n",
        "    grid_search = GridSearchCV(\n",
        "        knn, param_grid, cv=cv_folds,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        n_jobs=-1, verbose=1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_scaled, y)\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = np.sqrt(-grid_search.best_score_)\n",
        "\n",
        "    print(f\"최적 파라미터: {best_params}\")\n",
        "    print(f\"최적 RMSE (CV): {best_score:.3f}°C\")\n",
        "\n",
        "    # K 값에 따른 성능 시각화\n",
        "    k_scores = []\n",
        "    for k in k_range:\n",
        "        knn_temp = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
        "        scores = cross_val_score(knn_temp, X_scaled, y, cv=cv_folds, scoring='neg_mean_squared_error')\n",
        "        k_scores.append(np.sqrt(-scores.mean()))\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(k_range, k_scores, 'bo-', linewidth=2, markersize=6)\n",
        "    plt.xlabel('K-value')\n",
        "    plt.ylabel('RMSE (Cross Validation)')\n",
        "    plt.title('Model Performance by K Value')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    optimal_k = best_params['n_neighbors']\n",
        "    plt.axvline(x=optimal_k, color='r', linestyle='--', alpha=0.8, label=f'Optimize K={optimal_k}')\n",
        "    plt.legend()\n",
        "\n",
        "    # 검증 곡선 (overfitting 확인)\n",
        "    from sklearn.model_selection import validation_curve\n",
        "    train_scores, val_scores = validation_curve(\n",
        "        KNeighborsRegressor(weights='distance'), X_scaled, y,\n",
        "        param_name='n_neighbors', param_range=k_range,\n",
        "        cv=cv_folds, scoring='neg_mean_squared_error'\n",
        "    )\n",
        "\n",
        "    train_rmse = np.sqrt(-train_scores.mean(axis=1))\n",
        "    val_rmse = np.sqrt(-val_scores.mean(axis=1))\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(k_range, train_rmse, 'o-', label='Train RMSE', alpha=0.8)\n",
        "    plt.plot(k_range, val_rmse, 's-', label='Val  RMSE', alpha=0.8)\n",
        "    plt.xlabel('K Value')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('Train vs Validation')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return best_params\n",
        "\n",
        "def train_knn_model(X, y, best_params, test_size=0.2):\n",
        "    \"\"\"\n",
        "    최적 파라미터로 KNN 모델 학습\n",
        "    \"\"\"\n",
        "    # 시계열 데이터이므로 시간 순서를 유지하여 분할\n",
        "    split_index = int(len(X) * (1 - test_size))\n",
        "    X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
        "    y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
        "\n",
        "    print(f\"Trian_data: {len(X_train)}개\")\n",
        "    print(f\"Test_data: {len(X_test)}개\")\n",
        "\n",
        "    # 데이터 정규화\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # 최적 파라미터로 모델 학습\n",
        "    knn = KNeighborsRegressor(**best_params)\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # 예측\n",
        "    y_pred_train = knn.predict(X_train_scaled)\n",
        "    y_pred_test = knn.predict(X_test_scaled)\n",
        "\n",
        "    # 성능 평가\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
        "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "    train_r2 = r2_score(y_train, y_pred_train)\n",
        "    test_r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "    print(\"\\n=== 모델 성능 평가 ===\")\n",
        "    print(f\"훈련 데이터 - RMSE: {train_rmse:.3f}°C, MAE: {train_mae:.3f}°C, R²: {train_r2:.3f}\")\n",
        "    print(f\"테스트 데이터 - RMSE: {test_rmse:.3f}°C, MAE: {test_mae:.3f}°C, R²: {test_r2:.3f}\")\n",
        "\n",
        "    return (knn, scaler, X_train, X_test, y_train, y_test,\n",
        "            y_pred_train, y_pred_test, split_index)\n",
        "\n",
        "def visualize_results(df, y_train, y_test, y_pred_train, y_pred_test, split_index):\n",
        "    \"\"\"\n",
        "    예측 결과 시각화\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    # 1. 실제 vs 예측 (훈련 데이터)\n",
        "    axes[0, 0].scatter(y_train, y_pred_train, alpha=0.6, s=20)\n",
        "    min_val, max_val = y_train.min(), y_train.max()\n",
        "    axes[0, 0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "    axes[0, 0].set_xlabel('Real Mean Temp (°C)')\n",
        "    axes[0, 0].set_ylabel('Predict Mean Temp (°C)')\n",
        "    axes[0, 0].set_title('1. Train: Real vs Predict')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. 실제 vs 예측 (테스트 데이터)\n",
        "    axes[0, 1].scatter(y_test, y_pred_test, alpha=0.6, s=20, color='orange')\n",
        "    min_val, max_val = y_test.min(), y_test.max()\n",
        "    axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "    axes[0, 1].set_xlabel('Real Mean Temp (°C)')\n",
        "    axes[0, 1].set_ylabel('Predict Mean Temp  (°C)')\n",
        "    axes[0, 1].set_title('2. Test: Real vs Predict')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. 시계열 예측 결과\n",
        "    train_dates = df['date'].iloc[30:30+split_index]\n",
        "    test_dates = df['date'].iloc[30+split_index:]\n",
        "\n",
        "    axes[0, 2].plot(train_dates, y_train, label='Trian', alpha=0.7, linewidth=1)\n",
        "    axes[0, 2].plot(test_dates, y_test, label='Test', color='orange', linewidth=2)\n",
        "    axes[0, 2].plot(test_dates, y_pred_test, label='Predict', color='red',\n",
        "                   linestyle='--', linewidth=2)\n",
        "    axes[0, 2].set_xlabel('Date')\n",
        "    axes[0, 2].set_ylabel('Mean_temp(°C)')\n",
        "    axes[0, 2].set_title('3. Time Serial Predict')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. 잔차 분석\n",
        "    residuals_test = y_test - y_pred_test\n",
        "    axes[1, 0].scatter(y_pred_test, residuals_test, alpha=0.6, s=20, color='green')\n",
        "    axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "    axes[1, 0].set_xlabel('Predict_mean_temp (°C)')\n",
        "    axes[1, 0].set_ylabel('Residual(real-predict)')\n",
        "    axes[1, 0].set_title('4, Residual Analysis')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 5. 잔차 히스토그램\n",
        "    axes[1, 1].hist(residuals_test, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    axes[1, 1].set_xlabel('Residuals (°C)')\n",
        "    axes[1, 1].set_ylabel('Frequency')\n",
        "    axes[1, 1].set_title('5. Residual Distribution')\n",
        "    axes[1, 1].axvline(x=0, color='r', linestyle='--', lw=2)\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 6. 월별 성능 분석\n",
        "    test_dates_series = pd.Series(test_dates.values)\n",
        "    monthly_rmse = []\n",
        "    months = []\n",
        "\n",
        "    y_test_reset = y_test.reset_index(drop=True)\n",
        "    y_pred_test_series = pd.Series(y_pred_test)\n",
        "\n",
        "    for month in range(1, 13):\n",
        "        month_mask = test_dates_series.dt.month == month\n",
        "        if month_mask.sum() > 0:\n",
        "            month_y_test = y_test_reset[month_mask]\n",
        "            month_y_pred = y_pred_test_series[month_mask]\n",
        "            month_rmse = np.sqrt(mean_squared_error(month_y_test, month_y_pred))\n",
        "            monthly_rmse.append(month_rmse)\n",
        "            months.append(month)\n",
        "\n",
        "    axes[1, 2].bar(months, monthly_rmse, alpha=0.7, color='lightcoral')\n",
        "    axes[1, 2].set_xlabel('Month')\n",
        "    axes[1, 2].set_ylabel('RMSE (°C)')\n",
        "    axes[1, 2].set_title('Monthly Prediction Performance')\n",
        "    axes[1, 2].set_xticks(months)\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 성능 요약 출력\n",
        "    print(\"\\n=== 상세 성능 분석 ===\")\n",
        "    print(f\"잔차 평균: {residuals_test.mean():.3f}°C\")\n",
        "    print(f\"잔차 표준편차: {residuals_test.std():.3f}°C\")\n",
        "    print(f\"절대 오차 중앙값: {np.median(np.abs(residuals_test)):.3f}°C\")\n",
        "    print(f\"95% 예측 구간: ±{np.percentile(np.abs(residuals_test), 95):.3f}°C\")\n",
        "\n",
        "def predict_future_temperature(model, scaler, df, feature_cols, days_ahead=30):\n",
        "    \"\"\"\n",
        "    미래 기온 예측 (Autoregressive)\n",
        "    \"\"\"\n",
        "    print(f\"\\n미래 {days_ahead}일간 기온 예측 중...\")\n",
        "\n",
        "    # 원본 데이터프레임의 기본 컬럼만 사용하여 예측을 위한 데이터프레임 생성\n",
        "    base_cols = ['date', 'mean_tmp', 'min_tmp', 'max_tmp', 'area']\n",
        "    future_df = df[base_cols].copy()\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(days_ahead):\n",
        "        # 1. 현재까지의 데이터를 기반으로 특성 생성\n",
        "        df_with_features = create_features(future_df)\n",
        "\n",
        "        # 2. 마지막 데이터 포인트를 사용하여 예측\n",
        "        features_for_prediction = df_with_features[feature_cols].iloc[-1:]\n",
        "\n",
        "        # 3. 스케일링 및 예측\n",
        "        scaled_features = scaler.transform(features_for_prediction)\n",
        "        predicted_temp = model.predict(scaled_features)[0]\n",
        "        predictions.append(predicted_temp)\n",
        "\n",
        "        # 4. 다음 날짜에 대한 새로운 행 생성\n",
        "        last_date = future_df['date'].iloc[-1]\n",
        "        next_date = last_date + timedelta(days=1)\n",
        "\n",
        "        new_row = {\n",
        "            'date': next_date,\n",
        "            'mean_tmp': predicted_temp,\n",
        "            'min_tmp': predicted_temp - 5,  # 단순 추정\n",
        "            'max_tmp': predicted_temp + 5,  # 단순 추정\n",
        "            'area': future_df['area'].iloc[-1]\n",
        "        }\n",
        "\n",
        "        # 5. 예측된 행을 데이터프레임에 추가하여 다음 반복에 사용\n",
        "        future_df = pd.concat([future_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "        if (i + 1) % 7 == 0:\n",
        "            print(f\"{i+1}일 후 ({next_date.strftime('%Y-%m-%d')}): {predicted_temp:.1f}°C\")\n",
        "\n",
        "    # 예측 결과 시각화\n",
        "    prediction_dates = future_df['date'].iloc[-days_ahead:]\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # 최근 60일 실제 데이터\n",
        "    recent_data = df.tail(60)\n",
        "    plt.plot(recent_data['date'], recent_data['mean_tmp'],\n",
        "             'b-', label='Real Temp', linewidth=2, alpha=0.8)\n",
        "\n",
        "    # 미래 예측 데이터\n",
        "    plt.plot(prediction_dates, predictions,\n",
        "             'r--', label='Predict Temp', linewidth=2, marker='o', markersize=4)\n",
        "\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Mean Temp (°C)')\n",
        "    plt.title(f'Predcit Temp of Wonju (Future {days_ahead}day)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n예측 요약:\")\n",
        "    print(f\"Predict Mean Temp: {np.mean(predictions):.1f}°C\")\n",
        "    print(f\"Predict Max Temp: {np.max(predictions):.1f}°C\")\n",
        "    print(f\"Predict Min Temp: {np.min(predictions):.1f}°C\")\n",
        "\n",
        "    return predictions, prediction_dates\n",
        "\n",
        "def analyze_feature_importance(model, scaler, X, y, feature_cols, top_n=20):\n",
        "    \"\"\"\n",
        "    특성 중요도 분석 (Permutation Importance)\n",
        "    \"\"\"\n",
        "    from sklearn.inspection import permutation_importance\n",
        "\n",
        "    print(\"특성 중요도 분석 중...\")\n",
        "\n",
        "    X_scaled = scaler.transform(X)\n",
        "\n",
        "    # Permutation importance 계산\n",
        "    perm_importance = permutation_importance(\n",
        "        model, X_scaled, y, n_repeats=10, random_state=42, scoring='neg_mean_squared_error'\n",
        "    )\n",
        "\n",
        "    # 중요도 정리\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_cols,\n",
        "        'importance': perm_importance.importances_mean,\n",
        "        'std': perm_importance.importances_std\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    # 상위 특성들 시각화\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    top_features = importance_df.head(top_n)\n",
        "\n",
        "    plt.barh(range(len(top_features)), top_features['importance'],\n",
        "             xerr=top_features['std'], alpha=0.7, color='skyblue')\n",
        "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "    plt.xlabel('Permutation Importance')\n",
        "    plt.title(f'Top {top_n} Importance Feature')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nTop {min(10, len(importance_df))}Importance Feature:\")\n",
        "    for i, (_, row) in enumerate(importance_df.head(10).iterrows()):\n",
        "        print(f\"{i+1:2d}. {row['feature']:25s}: {row['importance']:.4f} ± {row['std']:.4f}\")\n",
        "\n",
        "    return importance_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 메인 실행 함수\n",
        "\n",
        "\"\"\"\n",
        "메인 실행 함수\n",
        "\"\"\"\n",
        "print(\"=== 원주 기온 데이터 KNN 예측 시스템 ===\\n\")\n",
        "\n",
        "# 1. 데이터 로드 및 전처리\n",
        "df = load_and_preprocess_data('/content/wonju_temp.csv')\n",
        "\n",
        "# 2. 특성 생성\n",
        "df_with_features = create_features(df)\n",
        "\n",
        "# 3. 머신러닝 데이터 준비\n",
        "X, y, feature_cols = prepare_ml_data(df_with_features, target_col='mean_tmp')\n",
        "\n",
        "# 4. 최적 하이퍼파라미터 탐색\n",
        "best_params = find_optimal_k(X, y, k_range=range(3, 21))\n",
        "\n",
        "# 5. 모델 학습\n",
        "(model, scaler, X_train, X_test, y_train, y_test,\n",
        "    y_pred_train, y_pred_test, split_index) = train_knn_model(X, y, best_params)\n",
        "\n",
        "# 6. 결과 시각화\n",
        "visualize_results(df_with_features, y_train, y_test, y_pred_train, y_pred_test, split_index)\n",
        "\n",
        "# 7. 특성 중요도 분석\n",
        "importance_df = analyze_feature_importance(model, scaler, X_test, y_test, feature_cols)\n",
        "\n",
        "# 8. 미래 예측\n",
        "predictions, dates = predict_future_temperature(\n",
        "    model, scaler, df_with_features, feature_cols, days_ahead=30\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BZpoA874ldFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DdL0Z1aVlf3O"
      }
    }
  ]
}